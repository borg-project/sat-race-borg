@inproceedings{Silverthorn2010latent,
  title={{Latent Class Models for Algorithm Portfolio Methods}},
  author={Silverthorn, Bryan and Miikkulainen, Risto},
  booktitle = {AAAI},
  year={2010}
}

@inproceedings{Cicirello2005Max,
	author = {Cicirello, Vincent   and Smith, Stephen  },
    booktitle = {AAAI},
	citeulike-article-id = {2521586},
	comment = {(private-note)Printed 3/12/2008.},
	keywords = {algorithm\_portfolios, bandit\_problem, extreme\_values, heuristic\_search, max\_bandit},
	posted-at = {2008-03-12 15:53:02},
	priority = {0},
	title = {{The Max K-Armed Bandit: a New Model for Exploration Applied to Search Heuristic Selection}},
	year = {2005}
}

@inproceedings{Elkan2006Clustering,
    author = {Elkan, Charles},
    booktitle = {ICML},
    citeulike-article-id = {2882880},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1143881},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1143844.1143881},
    comment = {(private-note)Printed 12/7/2008.},
    keywords = {clustering, dcm\_distribution, dirichlet, multinomial, text\_modeling, topic\_modeling},
    posted-at = {2008-12-07 22:44:51},
    priority = {3},
    title = {{Clustering Documents with an Exponential-Family Approximation of the Dirichlet Compound Multinomial Distribution}},
    year = {2006}
}

@inproceedings{Gagliolo2007Learning,
    author = {Gagliolo, Matteo and Schmidhuber, J\"{u}rgen},
    booktitle = {Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (IJCAI)},
    citeulike-article-id = {2307914},
    comment = {(private-note)Printed 1/29/2008.},
    keywords = {algorithm\_selection, bandit\_problem, restart\_strategies},
    posted-at = {2008-01-30 16:35:25},
    priority = {0},
    title = {{Learning Restart Strategies}},
    year = {2007}
}

@article{Gomes2001Algorithm,
	author = {Gomes, Carla and Selman, Bart},
	citeulike-article-id = {797118},
	comment = {(private-note)Printed 1/31/2008.},
	journal = {AI},
	keywords = {algorithm\_portfolios, static\_schedules},
	posted-at = {2008-01-21 21:04:24},
	priority = {0},
	title = {Algorithm portfolios},
	year = {2001}
}
    number = {1-2},
	volume = {126},

@inproceedings{Gomes1997Algorithm,
    author = {Gomes, Carla P. and Selman, Bart},
    booktitle = {Proceedings of the 13th Conference on Uncertainty in Artificial Intelligence (UAI)},
    citeulike-article-id = {1159912},
    editor = {Geiger, Dan and Shenoy, Prakash P.},
    keywords = {algorithm\_portfolios},
    pdf = {Gomes1997.pdf},
    posted-at = {2008-09-03 23:24:26},
    priority = {3},
    title = {{Algorithm Portfolio Design: Theory vs. Practice}},
    year = {1997}
}

@inproceedings{Gomes1998Boosting,
    author = {Gomes, Carla P. and Selman, Bart and Kautz, Henry},
    booktitle = {Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {3874730},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=295240.295710},
    keywords = {complete\_search, heuristic\_search, randomization, satisfiability},
    posted-at = {2009-01-11 23:37:36},
    priority = {0},
    title = {{Boosting Combinatorial Search Through Randomization}},
    year = {1998}
}

@inproceedings{Horvitz2001Bayesian,
    author = {Horvitz, Eric and Ruan, Yongshao and Gomes, Carla P. and Kautz, Henry A. and Selman, Bart and Chickering, David M.},
    booktitle = {UAI},
    citeulike-article-id = {2294168},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=720234},
    keywords = {algorithm\_portfolios, algorithm\_selection, bayesian},
    posted-at = {2008-01-27 00:42:42},
    priority = {0},
    title = {{A Bayesian Approach to Tackling Hard Computational Problems}},
    year = {2001}
}
    publisher = {Morgan Kaufmann Publishers Inc.},

@inproceedings{Kautz2002Dynamic,
    author = {Kautz, Henry and Horvitz, Eric and Ruan, Yongshao and Gomes, Carla and Selman, Bart},
    booktitle = {Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {2708032},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=777092.777196},
    comment = {(private-note)Printed 4/23/2008.},
    keywords = {restart\_strategies, satisfiability},
    posted-at = {2008-04-23 17:02:00},
    priority = {0},
    title = {Dynamic restart policies},
    year = {2002}
}

@article{Clarke2001Bounded,
  title={{Bounded model checking using satisfiability solving}},
  author={Clarke, Edmund and Biere, Armin and Raimi, Richard and Zhu, Yunshan},
  journal={Formal Methods in System Design},
  volume={19},
  number={1},
  year={2001},
}

@article{Kautz1996Pushing,
  title={{Pushing the envelope: planning, propositional logic, and stochastic search}},
  author={Kautz, Henry and Selman, Bart},
  booktitle={AAAI)},
  year={1996}
}

@article{Gagliolo2006Learning,
  title={{Learning dynamic algorithm portfolios}},
  author={Gagliolo, Matteo and Schmidhuber, J\"{u}rgen},
  journal={AMAI},
  year={2006},
}
  volume={47},
  number={3},

@inproceedings{Streeter2007Combining,
    author = {Streeter, Matthew and Golovin, Daniel and Smith, Stephen F.},
    booktitle = {AAAI},
    citeulike-article-id = {2316867},
    comment = {(private-note)Printed 1/31/2008.},
    keywords = {algorithm\_portfolios, decision\_problems, no\_regret, pac\_bounds},
    posted-at = {2008-01-31 23:47:56},
    priority = {0},
    title = {{Combining Multiple Heuristics Online}},
    year = {2007}
}

@phdthesis{Streeter2007Using,
    author = {Streeter, Matthew},
    citeulike-article-id = {2294447},
    keywords = {algorithm\_portfolios, online\_algorithms, phd\_theses},
    month = {December},
    posted-at = {2008-01-27 06:26:20},
    priority = {2},
    school = {Carnegie Mellon University},
    title = {{Using Online Algorithms to Solve NP-Hard Problems More Efficiently in Practice}},
    year = {2007}
}

@inproceedings{Streeter2007Restart,
    author = {Streeter, Matthew and Golovin, Daniel and Smith, Stephen F.},
    booktitle = {Proceedings of the Twenty-Second National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {3394550},
    comment = {(private-note)Printed 10/10/2008.},
    keywords = {restart\_strategies},
    posted-at = {2008-10-10 20:32:02},
    priority = {0},
    title = {{Restart Schedules for Ensembles of Problem Instances}},
    year = {2007}
}

@inproceedings{Streeter2006Asymptotically,
    author = {Streeter, Matthew J. and Smith, Stephen F.},
    booktitle = {Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {2521658},
    comment = {(private-note)Printed 10/10/2008.},
    keywords = {bandit\_problem, extreme\_values, max\_bandit},
    posted-at = {2008-03-12 16:13:36},
    priority = {0},
    title = {An Asymptotically Optimal Algorithm for the Max k-Armed Bandit Problem},
    year = {2006}
}

@inproceedings{Streeter2006Simple,
    abstract = {The max k-armed bandit problem is a recently-introduced online optimization problem with practical applications to heuristic search. Given a set of k slot machines, each yielding payoff from a fixed (but unknown) distribution, we wish to allocate trials to the machines so as to maximize the maximum payoff received over a series of n trials. Previous work on the max k-armed bandit problem has assumed that payoffs are drawn from generalized extreme value (GEV) distributions. In this paper we present a simple algorithm, based on an algorithm for the classical k-armed bandit problem, that solves the max k-armed bandit problem effectively without making strong distributional assumptions. We demonstrate the effectiveness of our approach by applying it to the task of selecting among priority dispatching rules for the resource-constrained project scheduling problem with maximal time lags (RCPSP/max).},
    author = {Streeter, Matthew J. and Smith, Stephen F.},
    booktitle = {CP},
    citeulike-article-id = {2521602},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11889205\_40},
    comment = {(private-note)Printed 3/12/2008.},
    keywords = {bandit\_problem, max\_bandit},
    posted-at = {2008-03-12 15:58:37},
    priority = {0},
    title = {A Simple Distribution-Free Approach to the Max k-Armed Bandit Problem},
    year = {2006}
}

@inproceedings{Streeter2007Using2,
    author = {Streeter, Matthew and Smith, Stephen F.},
    citeulike-article-id = {2316875},
    comment = {(private-note)Printed 1/31/2008.},
    booktitle = {Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS)},
    keywords = {decision\_problems, planning, query\_strategies},
    posted-at = {2008-01-31 23:50:57},
    priority = {2},
    title = {Using decision procedures efficiently for optimization},
    year = {2007}
}

@article{Katz1996Distribution,
	abstract = {This paper addresses the problem of distribution of words and phrases in text, a problem of great general interest and of importance for many practical applications. The existing models for word distribution present observed sequences of words in text documents as an outcome of some stochastic processes; the corresponding distributions of numbers of word occurrences in the documents are modelled as mixtures of Poisson distributions whose parameter values are fitted to the data. We pursue a linguistically motivated approach to statistical language modelling and use observable text characteristics as model parameters. Multi-word technical terms, intrinsically content entities, are chosen for experimentation. Their occurrence and the occurrence dynamics are investigated using a 100-million word data collection consisting of a variety of about 13,000 technical documents. The derivation of models describing word distribution in text is based on a linguistic interpretation of the process of text formation, with the probabilities of word occurrence being functions of observable and linguistically meaningful text characteristics. The adequacy of the proposed models for the description of actually observed distributions of words and phrases in text is confirmed experimentally. The paper has two focuses: one is modelling of the distributions of content words and phrases among different documents; and another is word occurrence dynamics within documents and estimation of corresponding probabilities. Accordingly, among the application areas for the new modelling paradigm are information retrieval and speech recognition.},
	author = {Katz, Slava  },
	citeulike-article-id = {3874821},
	journal = {NLE},
	keywords = {burstiness, topic\_modeling},
	posted-at = {2009-01-12 02:51:16},
	priority = {2},
	title = {Distribution of content words and phrases in text and language modelling},
	year = {1996}
}
	number = {1},
	volume = {2},

@inproceedings{Kautz1992Planning,
    author = {Kautz, Henry and Selman, Bart},
    booktitle = {ECAI},
    citeulike-article-id = {2906268},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=145448.146725},
    comment = {(private-note)Cited in the IJCAI 09 paper.},
    keywords = {planning, sat\_encoding, satisfiability},
    posted-at = {2009-01-12 03:27:20},
    priority = {0},
    title = {{Planning as Satisfiability}},
    year = {1992}
}

@inproceedings{Madsen2005Modeling,
    author = {Madsen, Rasmus E. and Kauchak, David and Elkan, Charles},
    booktitle = {ICML},
    citeulike-article-id = {2882884},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1102351.1102420},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1102351.1102420},
    comment = {(private-note)Printed. Cited.},
    keywords = {burstiness, dcm\_distribution, dirichlet, multinomial, text\_modeling, topic\_modeling},
    posted-at = {2009-01-12 02:42:18},
    priority = {0},
    title = {{Modeling Word Burstiness Using the Dirichlet Distribution}},
    year = {2005}
}

@article{Minka2003Estimating,
	author = {Minka, Thomas  },
	citeulike-article-id = {3874868},
	keywords = {dcm\_distribution, dirichlet},
	posted-at = {2009-01-12 03:37:15},
	priority = {2},
	title = {Estimating a {Dirichlet} distribution},
	year = {2003}
}

@article{Rice1976Algorithm,
	author = {Rice, J. R. },
	citeulike-article-id = {2294263},
	comment = {(private-note)Can't find this article online.
---=note-separator=---
(private-note)Checked it out from the PCL on 4/21/2008.},
	journal = {Advances in Computers},
	keywords = {algorithm\_selection, classic},
	pages = {65--118},
	posted-at = {2008-01-27 02:51:46},
	priority = {2},
	title = {{The Algorithm Selection Problem}},
	volume = {15},
	year = {1976}
}

@inproceedings{Rice1979Methodology,
    author = {Rice, John R.},
    booktitle = {Proceedings of the IFIP TC 2.5 Working Conference on Performance Evaluation of Numerical Software},
    citeulike-article-id = {6083499},
    keywords = {algorithm\_selection},
    posted-at = {2009-11-08 00:21:54},
    priority = {2},
    title = {{Methodology for the algorithm selection problem}},
    year = {1979}
}

@inproceedings{Streeter2008New,
    author = {Streeter, Matthew and Smith, Stephen F.},
    booktitle = {Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence (UAI)},
    citeulike-article-id = {3206693},
    comment = {(private-note)Printed 9/25/2008.},
    keywords = {algorithm\_portfolios},
    posted-at = {2008-09-08 21:02:06},
    priority = {0},
    title = {{New Techniques for Algorithm Portfolio Design}},
    year = {2008}
}

@book{Barto1998Reinforcement,
  title={{Reinforcement Learning: An Introduction}},
  author={Barto, Andrew and Sutton, Richard},
  year={1998},
}

@book{Bishop2006Pattern,
  title={{Pattern Recognition and Machine Learning}},
  author={Bishop, Christopher M.},
  year={2006}
}

@book{McLachlan2004Finite,
  title={{Finite Mixture Models}},
  author={McLachlan, Geoffrey and Peel, David},
  year={2004},
}

@techreport{Yamamoto2005Dirichlet,
	author = {Yamamoto, Mikio   and Sadamitsu, Kugatsu  },
	citeulike-article-id = {4165992},
	comment = {(private-note)Printed in ACES on 3/11/2009.},
	institution = {University of Tsukuba},
	keywords = {dcm\_distribution, dirichlet, text\_modeling},
	number = {CS-TR-05-1},
	posted-at = {2009-03-11 17:57:24},
	priority = {0},
	title = {{D}irichlet mixtures in text modeling},
	year = {2005}
}

@phdthesis{Wallach2008Structured,
	author = {Wallach, Hanna},
	citeulike-article-id = {4065323},
	comment = {(private-note)Printed 2/17/2009.},
	keywords = {phd\_theses, text\_modeling, topic\_modeling},
	posted-at = {2009-02-17 16:34:20},
	priority = {0},
	title = {Structured Topic Models for Language},
    school = {University of Cambridge},
	year = {2008}
}

@inproceedings{Doyle2009Accounting,
    author = {Doyle, Gabriel and Elkan, Charles},
    booktitle = {ICML},
    citeulike-article-id = {4372404},
    comment = {(private-note)Printed 4/21/2009.
---=note-separator=---
(private-note)PDF is of the not-yet-published version.},
    keywords = {dcm\_distribution, dirichlet, latent\_dirichlet, topic\_modeling},
    posted-at = {2009-04-21 16:04:04},
    priority = {0},
    title = {{Accounting for Word Burstiness in Topic Models}},
    year = {2009}
}

@article{Huberman1997Economics,
	abstract = {10.1126/science.275.5296.51},
	author = {Huberman, Bernardo  and Lukose, Rajan  and Hogg, Tad  },
	citeulike-article-id = {2316890},
	comment = {(private-note)Printed 1/31/2008.},
	journal = {Science},
	keywords = {algorithm\_portfolios, economics},
	month = {January},
	posted-at = {2008-01-31 23:57:51},
	priority = {0},
	title = {{Economics Approach to Hard Computational Problems}},
	year = {1997}
}
	number = {5296},
	volume = {275},

@article{Lagoudakis2000Algorithm,
	author = {Lagoudakis, Michail  and Littman, Michael},
	journal = {ICML},
	citeulike-article-id = {2270071},
	comment = {(private-note)Algorithm selection applied to recursive problems such as (in this case) list sorting. Casts the problem as an MDP; actions are algorithm selections; state transitions are recursions.},
	keywords = {algorithm\_selection, least\_squares, markov\_decision\_processes, reinforcement\_learning, temporal\_difference},
	posted-at = {2008-01-21 21:00:36},
	priority = {0},
	title = {{Algorithm Selection using Reinforcement Learning}},
	year = {2000}
}

@article{Lagoudakis2001Learning,
    abstract = {The DPLL procedure is the most popular complete satisfiability (SAT) solver. While its worst case complexity is exponential, the actual running time is greatly affected by the ordering of branch variables during the search. Several branching rules have been proposed, but none is the best in all cases. This work investigates the use of automated methods for choosing the most appropriate branching rule at each node in the search tree. We consider a reinforcement-learning approach where a value function, which predicts the performance of each branching rule in each case, is learned through trial runs on a typical problem set of the target class of SAT problems. Our results indicate that, provided sufficient training on a given class, the resulting strategy performs as well as (and, in some cases, better than) the best branching rule for that class. Research supported in part by NSF grant IRI-9702576. The first author was also partially supported by the Lilian-Voudouri Foundation in Greece. The authors gratefully acknowledge the influence of Don Loveland, Ron Parr, and Henry Kautz in helping to shape this work.},
    author = {Lagoudakis, Michail and Littman, Michael},
    citeulike-article-id = {6086764},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S1571-0653(04)00332-4},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1571065304003324},
    journal = {Electronic Notes in Discrete Mathematics},
    keywords = {algorithm\_selection, reinforcement\_learning, satisfiability},
    month = {June},
    pages = {344--359},
    posted-at = {2009-11-09 00:11:45},
    priority = {2},
    title = {{Learning to Select Branching Rules in the DPLL Procedure for Satisfiability}},
    volume = {9},
    year = {2001}
}

@article{Ruvolo2008Optimization,
    author = {Paul Ruvolo and Ian Fasel and Javier Movellan},
    title = {{Optimization on a Budget: A Reinforcement Learning Approach}},
    journal = {NIPS},
    year = {2008}
}

@inproceedings{LeytonBrown2002Learning,
	author = {Leyton-Brown, Kevin   and Nudelman, Eugene   and Shoham, Yoav  },
	citeulike-article-id = {2705087},
	comment = {(private-note)Printed 4/22/2008.},
    booktitle = {CP},
	keywords = {algorithm\_behavior, empirical\_hardness},
	posted-at = {2008-04-23 03:19:11},
	priority = {0},
	title = {{Learning the Empirical Hardness of Optimization Problems: the Case of Combinatorial Auctions}},
	year = {2002}
}

@inproceedings{Wallach2009Evaluation,
    abstract = {A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable, several estimators for this probability have been used in the topic modeling literature, including the harmonic mean method and empirical likelihood method. In this paper, we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents, and propose two alternative methods that are both accurate and efficient.},
    author = {Wallach, Hanna M. and Murray, Iain and Salakhutdinov, Ruslan and Mimno, David},
    booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning (ICML)},
    citeulike-article-id = {5879732},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1553515},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1553374.1553515},
    comment = {(private-note)Printed in CSA.},
    keywords = {topic\_modeling},
    posted-at = {2009-10-29 16:05:53},
    priority = {0},
    title = {{Evaluation Methods for Topic Models}},
    year = {2009}
}

@article{Mitchell1996Generating,
    abstract = {We report results from large-scale experiments in satisfiability testing. As has been observed by others, testing the satisfiability of random formulas often appears surprisingly easy. Here we show that by using the right distribution of instances, and appropriate parameter values, it is possible to generate random formulas that are hard, that is, for which satisfiability testing is quite difficult. Our results provide a benchmark for the evaluation of satisfiability testing procedures.},
    author = {Mitchell, David and Selman, Bart and Levesque, Hector J.},
    citeulike-article-id = {6032644},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0004-3702(95)00045-3},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0004-3702(95)00045-3},
    journal = {Artificial Intelligence},
    keywords = {empirical\_hardness, satisfiability, seminal},
    month = {March},
    number = {1-2},
    pages = {17--29},
    posted-at = {2009-10-29 17:32:05},
    priority = {2},
    title = {{Generating Hard Satisfiability Problems}},
    volume = {81},
    year = {1996}
}

@inproceedings{Mimno2009Polylingual,
    author = {Mimno, David and Wallach, Hanna M. and Naradowsky, Jason and Smith, David A. and McCallum, Andrew},
    booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    citeulike-article-id = {5348627},
    citeulike-linkout-0 = {http://www.aclweb.org/anthology/D/D09/D09-1092.pdf},
    keywords = {topic\_modeling},
    posted-at = {2009-10-29 17:37:17},
    priority = {5},
    title = {{Polylingual Topic Models}},
    year = {2009}
}

@inproceedings{FeiFei2005A,
    author = {Fei-Fei, Li and Perona, Pietro},
    booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)},
    citeulike-article-id = {1401348},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1068508.1069129},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPR.2005.16},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1467486},
    comment = {(private-note)Discussed w/ Kristen Grauman 4/16/2009.},
    keywords = {bayesian, image\_modeling, scene\_categorization},
    posted-at = {2009-04-17 20:34:23},
    priority = {0},
    title = {{A Bayesian Hierarchical Model for Learning Natural Scene Categories}},
    volume = {2},
    year = {2005}
}

@inproceedings{Wang2006Topics,
    abstract = {This paper presents an LDA-style topic model that captures not only the low-dimensional structure of data, but also how the structure changes over time. Unlike other recent work that relies on Markov assumptions or discretization of time, here each topic is associated with a continuous distribution over timestamps, and for each generated document, the mixture distribution over topics is influenced by both word co-occurrences and the document's timestamp. Thus, the meaning of a particular topic can be relied upon as constant, but the topics' occurrence and correlations change significantly over time. We present results on nine months of personal email, 17 years of NIPS research papers and over 200 years of presidential state-of-the-union addresses, showing improved topics, better timestamp prediction, and interpretable trends.},
    author = {Wang, Xuerui and McCallum, Andrew},
    booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
    citeulike-article-id = {1459200},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1150450},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/conf/kdd/WangM06},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/1150402.1150450},
    keywords = {topic\_modeling},
    posted-at = {2009-10-29 18:01:13},
    priority = {2},
    title = {{Topics over Time: A Non-Markov Continuous-Time Model of Topical Trends}},
    year = {2006}
}

@article{Erosheva2004Mixedmembership,
    abstract = {PNAS is one of world's most cited multidisciplinary scientific journals. The PNAS official classification structure of subjects is reflected in topic labels submitted by the authors of articles, largely related to traditionally established disciplines. These include broad field classifications into physical sciences, biological sciences, social sciences, and further subtopic classifications within the fields. Focusing on biological sciences, we explore an internal soft-classification structure of articles based only on semantic decompositions of abstracts and bibliographies and compare it with the formal discipline classifications. Our model assumes that there is a fixed number of internal categories, each characterized by multinomial distributions over words (in abstracts) and references (in bibliographies). Soft classification for each article is based on proportions of the article's content coming from each category. We discuss the appropriateness of the model for the PNAS database as well as other features of the data relevant to soft classification.},
    author = {Erosheva, Elena and Fienberg, Stephen and Lafferty, John},
    citeulike-article-id = {698679},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.0307760101},
    citeulike-linkout-1 = {http://www.pnas.org/content/101/suppl.1/5220.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/101/suppl.1/5220.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/15020766},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=15020766},
    journal = {Proceedings of the National Academy of Sciences of the United States of America},
    keywords = {topic\_modeling},
    month = {April},
    number = {Suppl 1},
    pages = {5220--5227},
    posted-at = {2009-10-25 03:15:29},
    priority = {2},
    title = {Mixed-membership models of scientific publications},
    volume = {101},
    year = {2004}
}

@inproceedings{Sinz2009ProblemSensitive,
    abstract = {Search restarts have shown great potential in speeding up SAT solvers based on the DPLL procedure. However, most restart policies presented so far do not take the problem structure into account. In this paper we present several new problem-sensitive restart heuristics. They all observe different search parameters like conflict level or backtrack level over time and, based on their development, decide whether to perform a restart or not. We also present a Java tool to visualize these search parameters on a given SAT instance over time in order to analyze existing heuristics and develop new one.},
    author = {Sinz, Carsten and Iser, Markus},
    booktitle = {Proceedings of the Twelfth International Conference on Theory and Applications of Satisfiability Testing (SAT)},
    citeulike-article-id = {5709917},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-02777-2\_33},
    citeulike-linkout-1 = {http://www.springerlink.com/content/k9450j7717516373},
    comment = {(private-note)Printed in CSA on 9/2/2009.},
    keywords = {restart\_strategies, satisfiability},
    posted-at = {2009-09-02 20:22:53},
    priority = {2},
    title = {{Problem-Sensitive Restart Heuristics for the DPLL Procedure}},
    year = {2009}
}

@inproceedings{Nikolic2009InstanceBased,
    abstract = {Execution of most of the modern DPLL-based SAT solvers is guided by a number of heuristics. Decisions made during the search process are usually driven by some fixed heuristic policies. Despite the outstanding progress in SAT solving in recent years, there is still an appealing lack of techniques for selecting policies appropriate for solving specific input formulae. In this paper we present a methodology for instance-based selection of solver's policies that uses a data-mining classification technique. The methodology also relies on analysis of relationships between formulae, their families, and their suitable solving strategies. The evaluation results are very good, demonstrate practical usability of the methodology, and encourage further efforts in this direction.},
    author = {Nikoli\'{c}, Mladen and Mari\'{c}, Filip and Jani\v{c}i\'{c}, Predrag},
    booktitle = {Theory and Applications of Satisfiability Testing (SAT 2009)},
    citeulike-article-id = {5709929},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-02777-2\_31},
    citeulike-linkout-1 = {http://www.springerlink.com/content/uu2322r45t3vx116},
    comment = {(private-note)Printed in CSA on 9/2/2009.},
    journal = {Theory and Applications of Satisfiability Testing - SAT 2009},
    keywords = {algorithm\_selection, satisfiability},
    posted-at = {2009-09-02 20:25:00},
    priority = {2},
    title = {Instance-Based Selection of Policies for SAT Solvers},
    year = {2009}
}

@inproceedings{UBCSAT,
  author =    "Dave A. D. Tompkins and Holger H. Hoos",
  title =     "{UBCSAT: An Implementation and Experimentation Environment for SLS Algorithms for SAT and MAX-SAT}",
  booktitle = "Revised Selected Papers of the Seventh International Conference on the Theory and Applications of Satisfiability Testing (SAT)",
  year =      "2005", 
}

@inproceedings{Roberts2006Directing,
	author = {Roberts, Mark   and Howe, Adele},
	booktitle = {AAAI},
	citeulike-article-id = {3363675},
	keywords = {algorithm\_portfolios, meta\_planning, planning},
	posted-at = {2008-10-01 20:37:39},
	priority = {2},
	title = {{Directing a Portfolio with Learning}},
	year = {2006}
}

@article{Xu2008SATzilla,
    abstract = {It has been widely observed that there is no single "dominant" SAT solver; instead, different solvers perform best on different instances. Rather than following the traditional approach of choosing the best solver for a given class of instances, we advocate making this decision online on a per-instance basis. Building on previous work, we describe SATzilla, an automated approach for constructing per-instance algorithm portfolios for SAT that use so-called empirical hardness models to choose among their constituent solvers. This approach takes as input a distribution of problem instances and a set of component solvers, and constructs a portfolio optimizing a given objective function (such as mean runtime, percent of instances solved, or score in a competition). The excellent performance of SATzilla was independently verified in the 2007 SAT Competition, where our SATzilla07 solvers won three gold, one silver and one bronze medal. In this article, we go well beyond SATzilla07 by making the portfolio construction scalable and completely automated, and improving it by integrating local search solvers as candidate solvers, by predicting performance score instead of runtime, and by using hierarchical hardness models that take into account different types of SAT instances. We demonstrate the effectiveness of these new techniques in extensive experimental results on data sets including instances from the most recent SAT competition.},
    author = {Xu, Lin and Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
    citeulike-article-id = {6051481},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1622687},
    comment = {(private-note)Printed in CSA on 10/31/2009.},
    journal = {JAIR},
    keywords = {algorithm\_portfolios, satisfiability},
    posted-at = {2009-10-31 20:32:55},
    priority = {2},
    title = {{SATzilla: Portfolio-based Algorithm Selection for SAT}},
    year = {2008}
}
    number = {1},
    volume = {32},
    pages = {565--606},

@inproceedings{Xu2007Hierarchical,
    abstract = {Empirical hardness models predict a solver's runtime for a given instance of an -hard problem based on efficiently computable features. Previous research in the SAT domain has shown that better prediction accuracy and simpler models can be obtained when models are trained separately on satisfiable and unsatisfiable instances. We extend this work by training separate hardness models for each class, predicting the probability that a novel instance belongs to each class, and using these predictions to build a hierarchical hardness model using a mixture-of-experts approach. We describe and analyze classifiers and hardness models for four well-known distributions of SAT instances and nine high-performance solvers. We show that surprisingly accurate classifications can be achieved very efficiently. Our experiments show that hierarchical hardness models achieve higher prediction accuracy than the previous state of the art. Furthermore, the classifier's confidence correlates strongly with prediction error, giving a useful per-instance estimate of prediction error.},
    author = {Xu, Lin and Hoos, Holger and Leyton-Brown, Kevin},
    citeulike-article-id = {6083617},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-74970-7\_49},
    citeulike-linkout-1 = {http://www.springerlink.com/content/y2k8q08208l45356},
    booktitle = {CP},
    keywords = {empirical\_hardness, satisfiability},
    posted-at = {2009-11-08 02:29:16},
    priority = {2},
    title = {{Hierarchical Hardness Models for SAT}},
    year = {2007}
}

@inproceedings{Xu2009SATzilla2009,
    author = {Xu, Lin and Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
    booktitle = {SAT Competition 2009},
    citeulike-article-id = {5821401},
    comment = {(private-note)Printed in CSA on 9/19/2009.},
    howpublished = {Solver Description},
    keywords = {algorithm\_portfolios, satisfiability},
    posted-at = {2009-09-22 16:47:40},
    priority = {2},
    title = {{SATzilla2009: an Automatic Algorithm Portfolio for SAT}},
    year = {2009}
}

    booktitle = {Principles and Practice of Constraint Programming},
@inproceedings{Nudelman2004Understanding,
    abstract = {It is well known that the ratio of the number of clauses to the number of variables in a random k-SAT instance is highly correlated with the instance's empirical hardness. We consider the problem of identifying such features of random SAT instances automatically using machine learning. We describe and analyze models for three SAT solvers – kcnfs, oksolver and satz – and for two different distributions of instances: uniform random 3-SAT with varying ratio of clauses-to-variables, and uniform random 3-SAT with fixed ratio of clauses-to-variables. We show that surprisingly accurate models can be built in all cases. Furthermore, we analyze these models to determine which features are most useful in predicting whether an instance will be hard to solve. Finally we discuss the use of our models to build SATzilla, an algorithm portfolio for SATWe'd like to acknowledge very helpful assistance from Nando de Freitas, and our indebtedness to the authors of the algorithms in the SATzilla portfolio. We also thank the anonymous reviewers for helpful comments..},
    author = {Nudelman, Eugene and Leyton-Brown, Kevin and Hoos, Holger H. and Devkar, Alex and Shoham, Yoav},
    booktitle = {CP},
    citeulike-article-id = {4179301},
    citeulike-linkout-0 = {http://www.springerlink.com/content/8tbbq95nrx8c2rhk},
    comment = {(private-note)Printed in CSA on 11/1/2009.},
    keywords = {empirical\_hardness, satisfiability},
    posted-at = {2009-11-01 22:07:33},
    priority = {2},
    title = {{Understanding Random SAT: Beyond the Clauses-to-Variables Ratio}},
    year = {2004}
}

@inproceedings{Mimno2008Topic,
    abstract = {Although fully generative models have been successfully used to model the contents of text documents, they are often awkward to apply to combinations of text data and document metadata. In this paper we propose a Dirichlet-multinomial regression (DMR) topic model that includes a log-linear prior on document-topic distributions that is a function of observed features of the document, such as author, publication venue, references, and dates. We show that by selecting appropriate features, DMR topic models can meet or exceed the performance of several previously published topic models designed for specific data. 1},
    author = {Mimno, David and McCallum, Andrew},
    booktitle = {Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence (UAI)},
    citeulike-article-id = {6054114},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.140.6925},
    keywords = {topic\_modeling},
    posted-at = {2009-11-01 22:38:59},
    priority = {2},
    title = {{Topic Models Conditioned on Arbitrary Features with Dirichlet-multinomial Regression}},
    year = {2008}
}

@inproceedings{KhudaBukhsh2009SATenstein,
    author = {KhudaBukhsh, Ashiqur and Xu, Lin and Hoos, Holger and Leyton-Brown, Kevin},
    booktitle = {IJCAI},
    citeulike-article-id = {5821354},
    comment = {(private-note)Printed in CSA on 9/18/2009.},
    keywords = {algorithm\_synthesis, local\_search, satisfiability},
    posted-at = {2009-09-22 16:41:11},
    priority = {2},
    title = {{SATenstein: Automatically Building Local Search SAT Solvers From Components}},
    year = {2009}
}

@inproceedings{Hutter2007Boosting,
    abstract = {Parameterized heuristics abound in computer aided design and verification, and manual tuning of the respective parameters is difficult and time-consuming. Very recent results from the artificial intelligence (AI) community suggest that this tuning process can be automated, and that doing so can lead to significant performance improvements; furthermore, automated parameter optimization can provide valuable guidance during the development of heuristic algorithms. In this paper, we study how such an AI approach can improve a state-of-the-art SAT solver for large, real-world bounded model-checking and software verification instances. The resulting, automatically-derived parameter settings yielded runtimes on average 4.5 times faster on bounded model checking instances and 500 times faster on software verification problems than extensive hand-tuning of the decision procedure. Furthermore, the availability of automatic tuning influenced the design of the solver, and the automatically-derived parameter settings provided a deeper insight into the properties of problem instances.},
    author = {Hutter, Frank and Babi\'{c}, Domagoj and Hoos, Holger H. and Hu, Alan J.},
    booktitle = {Proceedings of Formal Methods in Computer Aided Design (FMCAD)},
    citeulike-article-id = {6057267},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1333874.1334161},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/FMCAD.2007.13},
    keywords = {parameter\_adjustment, satisfiability},
    posted-at = {2009-11-02 19:11:31},
    priority = {2},
    title = {{Boosting Verification by Automatic Tuning of Decision Procedures}},
    year = {2007}
}

@inproceedings{Hutter2006Performance,
    abstract = {Machine learning can be used to build models that predict the run-time of search algorithms for hard combinatorial problems. Such empirical hardness models have previously been studied for complete, deterministic search algorithms. In this work, we demonstrate that such models can also make surprisingly accurate predictions of the run-time distributions of incomplete and randomized search methods, such as stochastic local search algorithms. We also show for the first time how information about an algorithm's parameter settings can be incorporated into a model, and how such models can be used to automatically adjust the algorithm's parameters on a per-instance basis in order to optimize its performance. Empirical results for Novelty+ and SAPS on structured and unstructured SAT instances show very good predictive performance and significant speedups of our automatically determined parameter settings when compared to the default and best fixed distribution-specific parameter settings.},
    author = {Hutter, Frank and Hamadi, Youssef and Hoos, Holger H. and Leyton-Brown, Kevin},
    booktitle = {Principles and Practice of Constraint Programming (CP)},
    citeulike-article-id = {2711112},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11889205\_17},
    journal = {Principles and Practice of Constraint Programming - CP 2006},
    keywords = {parameter\_adjustment, performance\_prediction},
    pages = {213--228},
    posted-at = {2008-04-24 01:55:50},
    priority = {2},
    title = {{Performance Prediction and Automated Tuning of Randomized and Parametric Algorithms}},
    year = {2006}
}

@article{Kautz2007The,
    abstract = {The papers in this special issue originated at  SAT 2001 , the Fourth International Symposium on the Theory and Applications of Satisfiability Testing. This foreword reviews the current state of satisfiability testing and places the papers in this issue in context.},
    author = {Kautz, Henry and Selman, Bart},
    citeulike-article-id = {6058093},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dam.2006.10.004},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0166218X06004586},
    journal = {DAM},
    keywords = {satisfiability, surveys},
    month = {June},
    posted-at = {2009-11-03 02:07:42},
    priority = {2},
    title = {{The state of SAT}},
    year = {2007}
}
    number = {12},
    volume = {155},
    pages = {1514--1524},

@inproceedings{Matos2008A,
    author = {Matos, Paulo and Planes, Jordi and Letombe, Florian and Marques-Silva, Jo\~{a}o},
    booktitle = {Proceedings of 18th European Conference on Artificial Intelligence (ECAI)},
    citeulike-article-id = {3466839},
    keywords = {algorithm\_portfolios, max\_sat},
    month = {July},
    posted-at = {2008-10-30 21:49:33},
    priority = {0},
    title = {{A MAX-SAT Algorithm Portfolio}},
    year = {2008}
}

@article{Brelaz1979New,
    abstract = {This paper describes efficient new heuristic methods to color the vertices of a graph which rely upon the comparison of the degrees and structure of a graph. A method is developed which is exact for bipartite graphs and is an important part of heuristic procedures to find maximal cliques in general graphs. Finally an exact method is given which performs better than the Randall-Brown algorithm and is able to color larger graphs, and the new heuristic methods, the classical methods, and the exact method are compared.},
    author = {Br\'{e}laz, Daniel},
    citeulike-article-id = {6083384},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=359094.359101},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/359094.359101},
    journal = {Communications of the ACM (CACM)},
    keywords = {graph\_coloring, heuristic\_search},
    number = {4},
    pages = {251--256},
    posted-at = {2009-11-07 22:20:31},
    priority = {2},
    title = {{New Methods to Color the Vertices of a Graph}},
    volume = {22},
    year = {1979}
}

@article{Weerawarana1996PYTHIA,
    abstract = {Problem-solving e Pub Caret nvironments (PSEs) interact with the user in a language  ” natural” to the associated discipline, and they provide a high-level abstraction of the underlying, computationally complex model. The knowledge-based system PYTHIA addresses the problem of (parameter, algorithm) pair selection within a scientific computing domain assuming some minimum user-specified computational objectives and some characteristics of the given problem. PYTHIA's framework and methodology are general and applicable to any class of scientific problems and solvers. PYTHIA is applied in the context of Parallel ELLPACK where there are many alternatives for the numerical solution of elliptic partial differential equations (PDEs). PYTHIA matches the characteristics of the given problem  with those of PDEs in an existing problem population and then uses performance profiles of the various solvers to select the appropriate method given user-specified error and solution time bounds. The profiles are automatically generated for each solver of the Parallel ELLPACK library.   — Pub Fmt italic Authors' Abstract Pub Fmt /italic},
    author = {Weerawarana, Sanjiva and Houstis, Elias N. and Rice, John R. and Joshi, Anupam and Houstis, Catherine E.},
    citeulike-article-id = {6083559},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=235815.235820},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/235815.235820},
    journal = {ACM Transactions on Mathematical Software},
    keywords = {algorithm\_selection},
    number = {4},
    pages = {447--468},
    posted-at = {2009-11-08 00:55:20},
    priority = {2},
    title = {{PYTHIA: A Knowledge-Based System to Select Scientific Algorithms}},
    volume = {22},
    year = {1996}
}

@article{Houstis2000PYTHIAII,
    abstract = {Often scientists need to locate appropriate software for their problems and then select from among many alternatives. We have previously proposed an approach for dealing with this task by processing performance data of the targeted software. This approach has been tested using a customized implementation referred to as PYTHIA. This experience made us realize the complexity of the algorithmic discovery of knowledge from performance data and of the management of these data together with the discovered knowledge. To address this issue, we created PYTHIA-II—a modular framework and system which combines a general  knowledge discovery in databases  (KDD) methodology and  recommender  system technologies to provide advice about scientific software/hardware  artifacts. The functionality and effectiveness of the system is demonstrated for two existing performance studies using sets of software for solving partial differential equations. From the end-user perspective, PYTHIA-II allows users to specify the problem to be solved and their computational objectives. In turn, PYTHIA-II (i) selects the software available for the user's problem (ii) suggests parameter values, and (iii) assesses the recommendation provided. PYTHIA-II provides all the necessary facilities to set up database schemas for testing suites and associated performance data in order to test sets of software. Moreover, it allows easy interfacing of alternative data mining and recommendation facilities. PYTHIA-II is an open-ended system implemented on public domain software and has  been used for performance evaluation in several different problem domains.},
    author = {Houstis, Elias N. and Catlin, Ann C. and Rice, John R. and Verykios, Vassilios S. and Ramakrishnan, Naren and Houstis, Catherine E.},
    citeulike-article-id = {6083587},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=353475},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/353474.353475},
    journal = {ACM Transactions on Mathematical Software},
    keywords = {algorithm\_selection},
    number = {2},
    pages = {227--253},
    posted-at = {2009-11-08 01:36:00},
    priority = {2},
    title = {{PYTHIA-II: A Knowledge/Database System for Managing Performance Data and Recommending Scientific Software}},
    volume = {26},
    year = {2000}
}

@article{CesaBianchi2004Minimizing,
    author = {Cesa-Bianchi, Nicol\`{o} and Lugosi, G\'{a}bor and Stoltz, Gilles},
    citeulike-article-id = {2491118},
    comment = {(private-note)Printed 3/8/2008.},
    journal = {Proceedings of the 17th Annual Conference on Learning Theory (COLT)},
    keywords = {best\_expert, label\_efficient},
    posted-at = {2008-03-08 22:05:54},
    priority = {3},
    title = {Minimizing Regret with Label Efficient Prediction},
    year = {2004}
}

@article{Blum2007From,
    author = {Blum, Avrim and Mansour, Yishay},
    citeulike-article-id = {2562459},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1314543},
    comment = {(private-note)Printed 3/19/2008.},
    journal = {Journal of Machine Learning Research (JMLR)},
    keywords = {bandit\_problem, internal\_regret},
    pages = {1307--1324},
    posted-at = {2008-03-19 15:56:19},
    priority = {2},
    title = {{From External to Internal Regret}},
    volume = {8},
    year = {2007}
}

@inproceedings{Gagliolo2004Adaptive,
    abstract = {Given is a search problem or a sequence of search problems, as well as a set of potentially useful search algorithms. We propose a general framework for online allocation of computation time to search algorithms based on experience with their performance so far. In an example instantiation, we use simple linear extrapolation of performance for allocating time to various simultaneously running genetic algorithms characterized by different parameter values. Despite the large number of searchers tested in parallel, on various tasks this rather general approach compares favorably to a more specialized state-of-the-art heuristic; in one case it is nearly two orders of magnitude faster.},
    author = {Gagliolo, Matteo and Zhumatiy, Viktor and Schmidhuber, J\"{u}rgen},
    citeulike-article-id = {2270113},
    citeulike-linkout-0 = {http://www.springerlink.com/content/f71qqvx36cmufqwl},
    booktitle = {Proceedings of the 15th European Conference on Machine Learning (ECML)},
    keywords = {algorithm\_portfolios, genetic\_algorithms},
    posted-at = {2008-01-21 21:15:37},
    priority = {2},
    title = {{Adaptive Online Time Allocation to Search Algorithms}},
    year = {2004}
}

@inproceedings{Gagliolo2008Towards,
    abstract = {In recent work we have developed an online algorithm selection technique, in which a model of algorithm performance is learned incrementally while being used. The resulting exploration-exploitation trade-off is solved as a bandit problem. The candidate solvers are run in parallel on a single machine, as an algorithm portfolio, and computation time is shared among them according to their expected performances. In this paper, we extend our technique to the more interesting and practical case of multiple CPUs.},
    author = {Gagliolo, Matteo and Schmidhuber, J\"{u}rgen},
    booktitle = {International Symposium on Distributed Computing and Artificial Intelligence (DCAI)},
    citeulike-article-id = {6086427},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-85863-8\_75},
    citeulike-linkout-1 = {http://www.springerlink.com/content/a571476851638836},
    keywords = {algorithm\_portfolios, distributed\_computing},
    posted-at = {2009-11-08 17:31:40},
    priority = {2},
    title = {{Towards Distributed Algorithm Portfolios}},
    year = {2008}
}


@techreport{Gagliolo2008Algorithm,
    abstract = {Algorithm selection is typically based on models of algorithm performance, learned during a separate offline training sequence, which can be prohibitively expensive. In recent work, we adopted an online approach, in which a performance model is iteratively updated and used to guide selection on a sequence of problem instances. The resulting exploration-exploitation trade-off was represented as a bandit problem with expert advice, using an existing solver for this game, but this required the setting of an arbitrary bound on algorithm runtimes, thus invalidating the optimal regret of the solver. In this paper, we propose a simpler framework for representing algorithm selection as a bandit problem, with partial information, and an unknown bound on losses. We adapt an existing solver to this game, proving a bound on its expected regret, which holds also for the resulting algorithm selection technique. We present preliminary experiments with a set of SAT solvers on a mixed SAT-UNSAT benchmark.},
    author = {Gagliolo, Matteo and Schmidhuber, J\"{u}rgen},
    citeulike-article-id = {3089316},
    citeulike-linkout-0 = {http://arxiv.org/abs/0807.1494},
    institution = {IDSIA},
    keywords = {algorithm\_portfolios, bandit\_problem},
    month = {July},
    number = {IDSIA - 07 - 08},
    posted-at = {2008-09-03 23:20:57},
    priority = {0},
    title = {Algorithm Selection as a Bandit Problem with Unbounded Losses},
    year = {2008}
}

@inproceedings{Auer1995Gambling,
    abstract = {In the multi-armed bandit problem, a gambler must decide which arm

of K non-identical slot machines to play in a sequence of trials so as to

maximize his reward. This classical problem has received much attention

because of the simple model it provides of the trade-off between exploration

(trying out each arm to find the best one) and exploitation (playing the

arm believed to give the best payoff). Past solutions for the bandit problem

have almost always relied on assumptions about the...},
    author = {Auer, Peter and Bianchi, Nicol\`o C. and Freund, Yoav and Schapire, Robert E.},
    booktitle = {Proceedings of the 36th Annual Symposium on Foundations of Computer Science (FOCS)},
    citeulike-article-id = {888355},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.1488},
    comment = {(private-note)Printed 3/8/2008.},
    keywords = {adversarial, bandit\_problem, partial\_information},
    pages = {322--331},
    posted-at = {2008-03-08 21:57:06},
    priority = {0},
    title = {Gambling in a rigged casino: the adversarial multi-armed bandit problem},
    year = {1995}
}

@article{Wichert2005Application,
    abstract = {We consider an extension of conventional univariate Kaplan-Meier type estimators for the hazard rate and the survivor function to multivariate censored data with a censored random regressor. It is an Akritas (1994) type estimator which adapts the nonparametric conditional hazard rate estimator of Beran (1981) to more typical data situations in applied analysis. We show with simulations that the estimator has nice finite sample properties and our implementation appears to be fast. As an application we estimate nonparametric conditional quantile functions with German administrative unemployment duration data.},
    author = {Wichert, Laura and Wilke, Ralf A.},
    citeulike-article-id = {6086697},
    citeulike-linkout-0 = {http://ssrn.com/abstract=838125},
    citeulike-linkout-1 = {http://papers.ssrn.com/sol3/Delivery.cfm/SSRN\_ID1000857\_code377050.pdf?abstractid=838125\&mirid=1},
    journal = {Social Science Research Network Working Paper Series},
    keywords = {survival\_analysis},
    month = {November},
    posted-at = {2009-11-08 22:21:37},
    priority = {2},
    title = {{Application of a Simple Nonparametric Conditional Quantile Function Estimator in Unemployment Duration Analysis}},
    year = {2005}
}

@inproceedings{Himanshu2007SAT,
    author = {Jain, Himanshu and Clarke, Edmund},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{SAT Solver Descriptions: CMUSATBase and CMUSAT}},
    year = {2007}
}

@inproceedings{Anbulagan2007Dew,
    author = {Anbulagan},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{Dew\_Satz: Integration of Lookahead Saturation with Restrictions into Satz}},
    year = {2007}
}

@inproceedings{Dequen2007kcnfs,
    author = {Dequen, Gilles and Dubois, Olivier},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{kcnfs}},
    year = {2007}
}

@inproceedings{Heule2007March,
    author = {Heule, Marijn and van Maaren, Hans},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{march\_ks}},
    year = {2007}
}

@article{Een2007Extensible,
  title={{An Extensible SAT-solver}},
  author={E\'{e}n, Niklas and S\"{o}rensson, Niklas},
  journal={Lecture Notes in Computer Science},
  volume={2919},
  pages={502--518},
  year={2004},
}

@inproceedings{Bregman2007SAT,
    author = {Bregman, David R. and Mitchell, David G.},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{The SAT Solver MXC, Version 0.5}},
    year = {2007}
}

@inproceedings{Biere2007Pico,
    author = {Biere, Armin},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{PicoSAT Versions 535}},
    year = {2007}
}

@inproceedings{Pham2007Resolution,
    author = {Pham, Duc Nghia and Anbulagan},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{Resolution Enhanced SLS solver: R+AdaptNovelty$^+$}},
    year = {2007}
}

@inproceedings{Pipatsrisawat2007RSat,
    author = {Pipatsrisawat, Knot and Darwiche, Adnan},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{RSat 2.0: SAT Solver Description}},
    year = {2007}
}

@inproceedings{Tompkins2007Scaling,
    author = {Tompkins, Dave A. D. and Hutter, Frank and Hoos, Holger H.},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{Scaling and Probabilistic Smoothing (SAPS)}},
    year = {2007}
}

@inproceedings{Kern2007Sat,
    author = {Kern, Christian and Khaleghi, Mohammad and Kugele, Stefan and Schallhart, Christian and Tautschnig, Michael and Weis, Andreas},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{Sat7---Engineering a Modular SAT-Solver}},
    year = {2007}
}

@inproceedings{Huang2007TINISAT,
    author = {Jinbo Huang},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{TINISAT in SAT Competition 2007}},
    year = {2007}
}

@mastersthesis{Lawrence2004Efficient,
  title={{Efficient Algorithms for Clause-Learning SAT Solvers}},
  author={Lawrence, Ryan},
  school={Simon Fraser University},
  year={2004}
}

@inproceedings{Spence2007Ternary,
    author = {Ivor Spence},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{Ternary Tree Solver (tts-4-0)}},
    year = {2007}
}

@inproceedings{Hoos2007Adaptive,
    author = {Hoos, Holger H. and Tompkins, Dave A. D.},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{Adaptive Novelty$^+$}},
    year = {2007}
}

@inproceedings{Pham2007g,
    author = {Pham, Duc Nghia and Gretton, Charles},
    booktitle = {SAT Competition Solver Descriptions},
    title = {{gNovelty$^+$}},
    year = {2007}
}

@article{Blei2003Latent,
    abstract = {We describe  latent Dirichlet allocation  (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
    author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
    citeulike-article-id = {378143},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=944919.944937},
    comment = {(private-note)Printed.},
    journal = {Journal of Machine Learning Research (JMLR)},
    keywords = {clustering, dirichlet, latent\_dirichlet, text\_modeling, topic\_modeling},
    pages = {993--1022},
    posted-at = {2008-11-17 16:47:48},
    priority = {0},
    title = {Latent dirichlet allocation},
    volume = {3},
    year = {2003}
}

@article{Teh2006Hierarchical,
    author = {Teh, Yee W. and Jordan, Michael I. and Beal, Matthew J. and Blei, David M.},
    citeulike-article-id = {965794},
    citeulike-linkout-0 = {http://dx.doi.org/10.1198/016214506000000302},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/asa/jasa/2006/00000101/00000476/art00023},
    comment = {(private-note)Printed in CSA on 9/30/2009.},
    journal = {Journal of the American Statistical Association (JASA)},
    keywords = {bayesian, clustering, dirichlet, hierarchical\_dirichlet},
    month = {December},
    number = {476},
    pages = {1566--1581},
    posted-at = {2008-10-20 23:58:27},
    priority = {2},
    title = {Hierarchical Dirichlet Processes},
    volume = {101},
    year = {2006}
}

@inproceedings{Goldwater2006Interpolating,
    author = {Goldwater, Sharon and Griffiths, Thomas L. and Johnson, Mark},
    citeulike-article-id = {6095750},
    booktitle = {NIPS},
    keywords = {text\_modeling},
    posted-at = {2009-11-10 20:10:15},
    priority = {2},
    title = {{Interpolating Between Types and Tokens by Estimating Power-Law Generators}},
    year = {2006}
}

@book{DeGroot1970Optimal,
    author = {DeGroot, Morris H.},
    keywords = {classic, references},
    title = {{Optimal Statistical Decisions}},
    year = {1970}
}

@article{Kearns2002Sparse,
    abstract = {A critical issue for the application of Markov decision processes (MDPs) to realistic problems is how the complexity of planning scales with the size of the MDP. In stochastic environments with very large or infinite state spaces, traditional planning and reinforcement learning algorithms may be inapplicable, since their running time typically grows linearly with the state space size in the worst case. In this paper we present a new algorithm that, given only a generative model (a natural and common type of simulator) for an arbitrary MDP, performs on-line, near-optimal planning with a per-state running time that has no dependence on the number of states. The running time is exponential in the horizon time (which depends only on the discount factor ? and the desired degree of approximation to the optimal policy). Our algorithm thus provides a different complexity trade-off than classical algorithms such as value iteration—rather than scaling linearly in both horizon time and state space size, our running time trades an exponential dependence on the former in exchange for no dependence on the latter.},
    author = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y.},
    citeulike-article-id = {1584916},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1017932429737},
    comment = {(private-note)Printed.},
    journal = {Machine Learning},
    keywords = {markov\_decision\_processes, reinforcement\_learning},
    month = {November},
    number = {2},
    pages = {193--208},
    posted-at = {2007-11-13 20:25:34},
    priority = {0},
    title = {{A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes}},
    volume = {49},
    year = {2002}
}

@inproceedings{Kocsis2006Bandit,
    author = {Kocsis, Levente and Szepesvari, Csaba},
    citeulike-article-id = {1910455},
    comment = {(private-note)Printed.},
    booktitle = {Proceedings of the 17th European Conference on Machine Learning (ECML)},
    keywords = {bandit\_problem, monte\_carlo, planning, tree\_search, uct},
    pages = {282--293},
    posted-at = {2007-11-13 20:32:01},
    priority = {0},
    title = {Bandit based Monte-Carlo Planning},
    year = {2006}
}

@inproceedings{Li2006Pachinko,
    author = {Li, Wei and Mccallum, Andrew},
    booktitle = {Proceedings of the 23rd International Conference on Machine Learning (ICML)},
    citeulike-article-id = {2409746},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1143917},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1143844.1143917},
    comment = {(private-note)Printed in ACES on 3/10/2009.},
    keywords = {pachinko\_allocation, text\_modeling, topic\_modeling},
    pages = {577--584},
    posted-at = {2009-03-10 23:22:23},
    priority = {2},
    title = {{Pachinko Allocation: DAG-Structured Mixture Models of Topic Correlations}},
    year = {2006}
}

@inproceedings{Banerjee2007Topic,
    author = {Banerjee, Arindam and Basu, Sugato},
    booktitle = {Proceedings of the 7th SIAM International Conference on Data Mining (SDM)},
    citeulike-article-id = {3558680},
    comment = {(private-note)Printed.},
    keywords = {clustering, directional\_statistics, dirichlet, latent\_dirichlet, mises-fisher, text\_modeling, topic\_modeling},
    posted-at = {2008-11-17 15:24:02},
    priority = {0},
    title = {{Topic Models over Text Streams: A Study of Batch and Online Unsupervised Learning}},
    year = {2007}
}

@article{Banerjee2005Clustering,
    abstract = {Several large scale data mining applications, such as text categorization and gene expression analysis, involve high-dimensional data that is also inherently directional in nature. Often such data is L 2 normalized so that it lies on the surface of a unit hypersphere. Popular models such as (mixtures of) multi-variate Gaussians are inadequate for characterizing such data. This paper proposes a generative mixture-model approach to clustering directional data based on the von Mises-Fisher (vMF) distribution, which arises naturally for data distributed on the unit hypersphere. In particular, we derive and analyze two variants of the Expectation Maximization (EM) framework for estimating the mean and concentration parameters of this mixture. Numerical estimation of the concentration parameters is non-trivial in high dimensions since it involves functional inversion of ratios of Bessel functions. We also formulate two clustering algorithms corresponding to the variants of EM that we derive. Our approach provides a theoretical basis for the use of cosine similarity that has been widely employed by the information retrieval community, and obtains the spherical kmeans algorithm (kmeans with cosine similarity) as a special case of both variants. Empirical results on clustering of high-dimensional text and gene-expression data based on a mixture of vMF distributions show that the ability to estimate the concentration parameter for each vMF component, which is not present in existing approaches, yields superior results, especially for difficult clustering tasks in high-dimensional spaces.},
    author = {Banerjee, Arindam and Dhillon, Inderjit S. and Ghosh, Joydeep and Sra, Suvrit},
    citeulike-article-id = {3666407},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1046920.1088718},
    comment = {(private-note)Printed.},
    journal = {Journal of Machine Learning Research (JMLR)},
    keywords = {clustering, directional\_statistics, mises-fisher, text\_modeling, topic\_modeling},
    pages = {1345--1382},
    posted-at = {2008-11-23 17:00:13},
    priority = {0},
    title = {{Clustering on the Unit Hypersphere using von Mises-Fisher Distributions}},
    volume = {6},
    year = {2005}
}

@inproceedings{Luby1993Optimal,
    abstract = {Let <e1>A</e1> be a Las Vegas algorithm, i.e., <e1>A</e1> is a randomized algorithm that always produces the correct answer when its stops but whose running time is a random variable. The authors consider the problem of minimizing the expected time required to obtain an answer from <e1>A</e1> using strategies which simulate <e1>A</e1> as follows: run <e1>A</e1> for a fixed amount of time <e1>t</e1><sub>1</sub>, then run <e1>A</e1> independent for a fixed amount of time <e1>t</e1><sub>2 </sub>, etc. The simulation stops if <e1>A</e1> completes its execution during any of the runs. Let <e1>S</e1>=(<e1>t</e1><sub>1</sub>, <e1>t </e1><sub>2</sub>,. . .) be a strategy, and let <e1>l</e1><sub>A</sub>=inf<sub>S</sub><e1>T</e1>(<e1>A</e1>,<e1>S</e1>), where <e1>T</e1>(<e1>A</e1>,<e1>S</e1>) is the expected value of the running time of the simulation of <e1>A</e1> under strategy <e1>S</e1>. The authors describe a simple universal strategy <e1>S</e1><sup>univ </sup>, with the property that, for any algorithm <e1>A</e1>, <e1>T</e1>(<e1>A</e1>,<e1>S</e1><sup>univ</sup>)=O(<e1>l</e1><sub>A </sub>log(<e1>l</e1><sub>A</sub>)). Furthermore, they show that this is the best performance that can be achieved, up to a constant factor, by any universal strategy},
    author = {Luby, Michael and Sinclair, Alistair and Zuckerman, David},
    citeulike-article-id = {6100467},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ISTCS.1993.253477},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=253477},
    booktitle = {Proceedings of the 2nd Israel Symposium on Theory and Computing Systems},
    keywords = {restart\_strategies},
    posted-at = {2009-11-12 03:44:18},
    priority = {2},
    title = {{Optimal Speedup of Las Vegas Algorithms}},
    year = {1993}
}

@inproceedings{Li2007Combining,
    abstract = {The adaptive noise mechanism was introduced in Novelty+ to automatically adapt noise settings during the search [4]. The local search algorithm G 2 WSAT deterministically exploits promising decreasing variables to reduce randomness and consequently the dependence on noise parameters. In this paper, we first integrate the adaptive noise mechanism in G 2 WSAT to obtain an algorithm adaptG 2 WSAT, whose performance suggests that the deterministic exploitation of promising decreasing variables cooperates well with this mechanism. Then, we propose an approach that uses look-ahead for promising decreasing variables to further reinforce this cooperation. We implement this approach in adaptG 2 WSAT, resulting in a new local search algorithm called adaptG 2 WSAT P . Without any manual noise or other parameter tuning, adaptG 2 WSAT P shows generally good performance, compared with G 2 WSAT with approximately optimal static noise settings, or is sometimes even better than G 2 WSAT. In addition, adaptG 2 WSAT P is favorably compared with state-of-the-art local search algorithms such as R+adaptNovelty+ and VW.},
    author = {Li, Chu and Wei, Wanxia and Zhang, Harry},
    booktitle = {Proceedings of the Tenth International Conference on Theory and Applications of Satisfiability Testing (SAT)},
    citeulike-article-id = {6102484},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-72788-0\_15},
    citeulike-linkout-1 = {http://www.springerlink.com/content/l60287431756851m},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 17:38:10},
    priority = {2},
    title = {{Combining Adaptive Noise and Look-Ahead in Local Search for SAT}},
    year = {2007}
}

@inproceedings{Hoos2002An,
    author = {Hoos, Holger H.},
    booktitle = {Proceedings of the Eighteenth National Conference in Artificial Intelligence (AAAI)},
    citeulike-article-id = {6102942},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 17:51:07},
    priority = {2},
    title = {{An Adaptive Noise Mechanism for WalkSAT}},
    year = {2002}
}

@inproceedings{Papadimitriou1991On,
    author = {Papadimitriou, Christos H.},
    booktitle = {Proceedings of the 32nd Annual Symposium on Foundations of Computer Science (FOCS)},
    citeulike-article-id = {6102948},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 17:54:23},
    priority = {2},
    title = {{On Selecting a Satisfying Truth Assignment}},
    year = {1991}
}

@inproceedings{Schoning1999A,
    author = {Sch\"{o}ning, Uwe},
    booktitle = {Proceedings of the Fourtieth Annual Symposium on Foundations of Computer Science (FOCS)},
    citeulike-article-id = {6102954},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 17:57:56},
    priority = {2},
    title = {{A Probabilistic Algorithm for k-SAT and Constraint Satisfaction Problems}},
    year = {1999}
}

@inproceedings{Ishtaiwi2005Neighbourhood,
    author = {Ishtaiwi, Abdelraouf and Thornton, John and Sattar, Abdul and Pham, Duc N.},
    booktitle = {Proceedings of the Eleventh International Conference on Principles and Practice of Constraint Programming (CP)},
    citeulike-article-id = {6102963},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 18:04:10},
    priority = {2},
    title = {{Neighbourhood Clause Weight Redistribution in Local Search for SAT}},
    year = {2005}
}

@inproceedings{Tompkins2006On,
    author = {Tompkins, Dave A. D. and Hoos, Holger H.},
    citeulike-article-id = {6102966},
    booktitle = {Proceedings of the Nineteenth Conference of the Canadian Society for Computational Studies of Intelligence},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 18:07:00},
    priority = {2},
    title = {{On the Quality and Quantity of Random Decisions in Stochastic Local Search for SAT}},
    year = {2006}
}

@inproceedings{Li2005Diversification,
    author = {Li, Chu M. and Huang, Wen Q.},
    booktitle = {Proceedings of the Eighth International Conference on Theory and Applications of Satisfiability Testing (SAT)},
    citeulike-article-id = {6102974},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 18:11:24},
    priority = {2},
    title = {Diversification and Determinism in Local Search for Satisfiability},
    year = {2005}
}

@inproceedings{Selman1992A,
    author = {Selman, Bart and Levesque, Hector and Mitchell, David},
    booktitle = {Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6102991},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 18:16:43},
    priority = {2},
    title = {{A New Method for Solving Hard Satisfiability Problems}},
    year = {1992}
}

@inproceedings{Mazure1997Tabu,
    author = {Mazure, Bertrand and Sa\"{i}s, Lakhdar and Gr\'{e}goire, \'{E}ric},
    booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6102995},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 18:19:21},
    priority = {2},
    title = {{Tabu Search for SAT}},
    year = {1997}
}

@inproceedings{Selman1993DomainIndependent,
    author = {Selman, Bart and Kautz, Henry A.},
    booktitle = {Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI)},
    citeulike-article-id = {6103017},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 18:29:36},
    priority = {2},
    title = {{Domain-Independent Extensions to GSAT: Solving Large Structured Variables}},
    year = {1993}
}

@inproceedings{Gent1993Towards,
    author = {Gent, Ian P. and Walsh, Toby},
    booktitle = {Proceedings of the Eleventh National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6106064},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 19:52:50},
    priority = {2},
    title = {{Towards an Understanding of Hill-climbing Procedures for SAT}},
    year = {1993}
}

@incollection{Gent1995Unsatisfied,
    author = {Gent, Ian P. and Walsh, Toby},
    booktitle = {Hybrid Problems, Hybrid Solutions},
    citeulike-article-id = {6106086},
    keywords = {local\_search, satisfiability, ubcsat},
    pages = {73--85},
    posted-at = {2009-11-12 19:58:23},
    priority = {2},
    title = {{Unsatisfied Variables in Local Search}},
    year = {1995}
}

@inproceedings{Smyth2003Iterated,
    author = {Smyth, Kevin and Hoos, Holger H. and St\"{u}tzle, Thomas},
    booktitle = {Proceedings of the Sixteenth Conference of the Canadian Society for Computational Studies of Intelligence},
    citeulike-article-id = {6106096},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:01:07},
    priority = {2},
    title = {{Iterated Robust Tabu Search for MAX-SAT}},
    year = {2003}
}

@inproceedings{McAllester1997Evidence,
    author = {McAllester, David and Selman, Bart and Kautz, Henry},
    booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6106101},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:03:07},
    priority = {2},
    title = {{Evidence for Invariants in Local Search}},
    year = {1997}
}

@inproceedings{Hoos1999On,
    author = {Hoos, Holger H.},
    booktitle = {Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6106103},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:05:07},
    priority = {2},
    title = {{On the Run-time Behaviour of Stochastic Local Search Algorithms for SAT}},
    year = {1999}
}

@inproceedings{Thornton2004Additive,
    author = {Thornton, John and Pham, Duc N. and Bain, Stuart and Ferreira, Valnir},
    booktitle = {Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6106113},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:10:33},
    priority = {2},
    title = {{Additive versus Multiplicative Clause Weighting for SAT}},
    year = {2004}
}

@article{Taillard1991Robust,
    author = {Taillard, \'{E}ric D.},
    citeulike-article-id = {6106118},
    journal = {Parallel Computing},
    keywords = {local\_search, satisfiability, ubcsat},
    number = {4-5},
    pages = {443--455},
    posted-at = {2009-11-12 20:13:30},
    priority = {2},
    title = {{Robust taboo search for the quadratic assignment problem}},
    volume = {17},
    year = {1991}
}

@inproceedings{Tompkins2004Warped,
    author = {Tompkins, Dave A. D. and Hoos, Holger H.},
    booktitle = {Proceedings of the Eighth International Symposium on Artificial Intelligence and Mathematics (SAIM)},
    citeulike-article-id = {6106122},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:17:55},
    priority = {2},
    title = {{Warped Landscapes and Random Acts of SAT Solving}},
    year = {2004}
}

@inproceedings{Hutter2002Scaling,
    author = {Hutter, Frank and Tompkins, Dave A. D. and Hoos, Holger H.},
    booktitle = {Proceedings of the Eighth International Conference on Principles and Practice of Constraint Programming (CP)},
    citeulike-article-id = {6106126},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:21:17},
    priority = {2},
    title = {{Scaling and Probabilistic Smoothing: Efficient Dynamic Local Search for SAT}},
    year = {2002}
}

@article{Hansen1990Algorithms,
    author = {Hansen, Pierre and Jaumard, Brigitte},
    citeulike-article-id = {6106137},
    journal = {Computing},
    keywords = {local\_search, max\_sat, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:30:11},
    priority = {2},
    title = {{Algorithms for the Maximum Satisfiability Problem}},
    year = {1990}
}

@inproceedings{Prestwich2005Random,
    author = {Prestwich, Steven},
    booktitle = {Proceedings of the Eighth International Conference on Theory and Applications of Satisfiability Testing (SAT)},
    citeulike-article-id = {6106154},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:40:17},
    priority = {2},
    title = {{Random Walk With Continuously Smoothed Variable Weights}},
    year = {2005}
}

@inproceedings{Selman1994Noise,
    author = {Selman, Bart and Kautz, Henry A. and Cohen, Bram},
    booktitle = {Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6106159},
    keywords = {local\_search, satisfiability, ubcsat},
    posted-at = {2009-11-12 20:42:58},
    priority = {2},
    title = {{Noise Strategies for Improving Local Search}},
    year = {1994}
}

@inbook{Gomes2007Satisfiability,
    author = {Gomes, Carla P. and Kautz, Henry and Sabharwal, Ashish and Selman, Bart},
    citeulike-article-id = {4008717},
    journal = {Handbook of Knowledge Representation},
    keywords = {satisfiability, surveys},
    posted-at = {2009-02-04 18:30:27},
    priority = {0},
    title = {Satisfiability Solvers},
    year = {2007}
}

@article{Davis1962A,
    abstract = {The programming of a proof procedure is discussed in connection with trial runs and possible improvements.},
    author = {Davis, Martin and Logemann, George and Loveland, Donald},
    citeulike-article-id = {1761434},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=368557},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/368273.368557},
    journal = {Communications of the ACM (CACM)},
    keywords = {satisfiability, seminal},
    month = {July},
    number = {7},
    pages = {394--397},
    posted-at = {2009-10-24 00:25:13},
    priority = {2},
    title = {{A Machine Program for Theorem-Proving}},
    volume = {5},
    year = {1962}
}

@techreport{DIMACS1993Satisfiability,
    booktitle = {DIMACS Challenge},
    citeulike-article-id = {3367528},
    citeulike-linkout-0 = {ftp://dimacs.rutgers.edu/pub/challenge/satisfiability/doc/},
    comment = {(private-note)Printed 12/10/2008.},
    howpublished = {ftp://dimacs.rutgers.edu/pub/challenge/satisfiability/doc/},
    keywords = {satisfiability, standards},
    posted-at = {2008-10-02 22:53:14},
    priority = {0},
    author = {DIMACS},
    title = {{Satisfiability Suggested Format}},
    url = {ftp://dimacs.rutgers.edu/pub/challenge/satisfiability/doc/},
    year = {1993}
}

@misc{Sat2007Competition,
    title = {{Semi-Annual Competition}},
    author = {SAT},
    year = {2007},
    url = {http://www.satcompetition.org/2007/}
}

@misc{Sat2009Competition,
    title = {{Semi-Annual Competition}},
    author = {SAT},
    year = {2009},
    url = {http://www.satcompetition.org/2009/}
}

@inproceedings{Gomes1997Problem,
    author = {Gomes, Carla P. and Selman, Bart},
    booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {6112412},
    keywords = {satisfiability},
    posted-at = {2009-11-15 01:52:23},
    priority = {2},
    title = {{Problem Structure in the Presence of Perturbations}},
    year = {1997}
}

@misc{Hoos2000SATLIB,
    author = {Hoos, Holger H. and St\"{u}tzle, Thomas},
    booktitle = {SAT 2000},
    citeulike-article-id = {2458419},
    editor = {Gent, I. P. and Maaren, H. and Walsh, T.},
    keywords = {benchmarking, satisfiability},
    pages = {283--292},
    posted-at = {2008-03-02 21:01:46},
    priority = {0},
    title = {{SATLIB: An Online Resource for Research on SAT}},
    url = {http://www.cs.ubc.ca/\~hoos/SATLIB/benchm.html},
    year = {2000}
}

@inproceedings{BoydGraber2009Reading,
    author = {Boyd-Graber, Jordan and Chang, Jonathan and Gerrish, Sean and Wang, Chong and Blei, David},
    booktitle = {Advances in Neural Information Processing Systems (NIPS)},
    citeulike-article-id = {6131492},
    keywords = {topic\_modeling},
    posted-at = {2009-11-18 03:41:00},
    priority = {2},
    title = {{Reading Tea Leaves: How Humans Interpret Topic Models}},
    year = {2009}
}

@article{MarquesSilva1999GRASP,
    abstract = {This paper introduces GRASP (Generic seaRch Algorithm for the Satisfiability Problem), a new search algorithm for Propositional Satisfiability (SAT). GRASP incorporates several search-pruning techniques that proved to be quite powerful on a wide variety of SAT problems. Some of these techniques are specific to SAT, whereas others are similar in spirit to approaches in other fields of Artificial Intelligence. GRASP is premised on the inevitability of conflicts during the search and its most distinguishing feature is the augmentation of basic backtracking search with a powerful conflict analysis procedure. Analyzing conflicts to determine their causes enables GRASP to backtrack nonchronologically to earlier levels in the search tree, potentially pruning large portions of the search space. In addition, by  ” recording” the causes of conflicts, GRASP can recognize and preempt the occurrence of similar conflicts later on in the search. Finally, straightforward bookkeeping of the causality chains leading up to conflicts allows GRASP to identify assignments that are necessary for a solution to be found. Experimental results obtained from a large number of benchmarks indicate that application of the proposed conflict analysis techniques to SAT algorithms can be extremely effective for a large number of representative classes of SAT instances},
    author = {Marques-Silva, Jo\~{a}o P. and Sakallah, Karem A.},
    booktitle = {Transactions on Computers},
    citeulike-article-id = {1861626},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=769433},
    journal = {IEEE Transactions on Computers},
    keywords = {satisfiability},
    month = {August},
    number = {5},
    pages = {506--521},
    posted-at = {2009-11-18 04:19:05},
    priority = {2},
    title = {{GRASP: A Search Algorithm for Propositional Satisfiability}},
    volume = {48},
    year = {1999}
}

@inproceedings{Biere1999Symbolic,
    abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.},
    author = {Biere, Armin and Cimatti, Alessandro and Clarke, Edmund M. and Fujita, Masahiro and Zhu, Yunshan},
    booktitle = {ACM/IEEE Design Autom. Conference},
    citeulike-article-id = {1734831},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=309942},
    keywords = {design\_automation, satisfiability},
    posted-at = {2009-11-18 22:39:44},
    priority = {2},
    title = {{Symbolic Model Checking using SAT procedures instead of BDDs}},
    year = {1999}
}
    pages = {317--320},

@inproceedings{Veneris2003Fault,
    abstract = {Recent advances in Boolean satisfiability have made it attractive to solve many digital VLSI design problems such as verification and test generation. Fault diagnosis and logic debugging have not been addressed by existing satisfiability-based solutions. We attempt to bridge this gap by proposing a model-free satisfiability-based solution to these problems. The proposed formulation is intuitive and easy to implement. It shows that satisfiability captures significant problem characteristics and it offers different trade-offs. It also provides new opportunities for satisfiability-based diagnosis tools and diagnosis-specific satisfiability algorithms. Theory and experiments validate the claims and demonstrate its potential.},
    author = {Veneris, Andreas},
    citeulike-article-id = {6144121},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1250264},
    booktitle = {Proceedings of the 4th International Workshop on Microprocessor Test and Verification: Common Challenges and Solutions},
    keywords = {design\_automation, satisfiability},
    month = {May},
    posted-at = {2009-11-18 23:53:14},
    priority = {2},
    title = {{Fault Diagnosis and Logic Debugging Using Boolean Satisfiability}},
    year = {2003}
}

    booktitle = {International Symposium on Field-Programmable Gate Arrays},
@inproceedings{Wood1997FPGA,
    abstract = {Guaranteeing or even estimating the routability of a portion of a placed FPGA remains difficult or impossible in most practical applications. In this paper we develop a novel formulation of both routing and routability estimation that relies on a rendering of the routing constraints as a single large Boolean equation. Any satisfying assignment to this equation specifies a complete detailed routing. By representing the equation as a Binary Decision Diagram (BDD), we represent all possible routes for allnets simultaneously. Routability estimation is transformed to Boolean satisfiability, which is trivial for BDDs. We use the technique in the context of a perfect routability estimator for a global router. Experimental results from a standard FPGA benchmark suite suggest the technique is feasible for realistic circuits, but refinements are needed for very large designs.},
    author = {Wood, R. Glenn and Rutenbar, Rob A.},
    booktitle = {Int. Symposium on Field-Programmable Gate Arrays},
    citeulike-article-id = {6144133},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=258322},
    keywords = {design\_automation, sat\_encoding, satisfiability},
    posted-at = {2009-11-18 23:58:20},
    priority = {2},
    title = {{FPGA Routing and Routability Estimation Via Boolean Satisfiability}},
    year = {1997}
}

@inproceedings{Hutter2007Automatic,
    abstract = {The determination of appropriate values for free algorithm parameters is a challenging and tedious task in the design of effective algorithms for hard problems. Such parameters include categorical choices (e.g., neighborhood structure in local search or variable/value ordering heuristics in tree search), as well as numerical parameters (e.g., noise or restart timing). In practice, tuning of these parameters is largely carried out manually by applying rules of thumb and crude heuristics, while more principled approaches are only rarely used. In this paper, we present a local search approach for algorithm configuration and prove its convergence to the globally optimal parameter configuration. Our approach is very versatile: it can, e.g., be used for minimising run-time in decision problems or for maximising solution quality in optimisation problems. It further applies to arbitrary algorithms, including heuristic tree search and local search algorithms, with no limitation on the number of parameters. Experiments in four algorithm configuration scenarios demonstrate that our automatically determined parameter settings always outperform the algorithm defaults, sometimes by several orders of magnitude. Our approach also shows better performance and greater flexibility than the recent CALIBRA system. Our ParamILS code, along with instructions on how to use it for tuning your own algorithms, is available on-line at},
    author = {Hutter, Frank and Hoos, Holger H. and Stutzle, Thomas},
    booktitle = {Proceedings of the Twenty-Second National Conference on Artificial Intelligence (AAAI)},
    citeulike-article-id = {5847279},
    comment = {(private-note)Printed in CSA on 9/28/2009.},
    keywords = {local\_search, parameter\_adjustment},
    posted-at = {2009-09-28 16:23:18},
    priority = {2},
    title = {{Automatic Algorithm Configuration based on Local Search}},
    year = {2007}
}

@article{Hutter2009ParamILS,
    author = {Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin and St\"{u}tzle, Thomas},
    citeulike-article-id = {6176428},
    journal = {Journal of Artificial Intelligence Research},
    keywords = {local\_search, parameter\_adjustment},
    posted-at = {2009-11-21 03:35:32},
    priority = {2},
    title = {{ParamILS: An Automatic Algorithm Configuration Framework}},
    year = {2009}
}

@article{Guyon2003An,
    abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
    author = {Guyon, Isabelle and Elisseeff, Andr\'{e}},
    citeulike-article-id = {139944},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=944919.944968},
    journal = {Journal of Machine Learning Research (JMLR)},
    keywords = {feature\_selection, machine\_learning, surveys},
    pages = {1157--1182},
    posted-at = {2009-11-21 22:28:13},
    priority = {2},
    title = {{An Introduction to Variable and Feature Selection}},
    volume = {3},
    year = {2003}
}

